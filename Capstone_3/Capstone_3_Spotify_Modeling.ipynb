{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Preprocessing <br />\n",
    "In this notebook we will be taking our now analyzed data and preparing it for modeling (which will occur in the next notebook - Regression Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('capstone3_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are dropping our non-numerical/categorical features for our feature. We could theoretically implement some dummy features (particularly for feature artist), but I determined it would simply be unnecessary as our end user would be Illenium anyways, The only way that it could be helpful is if he were to collaborate wth other popular artists in the future, and they would still need to determine what aspects of a song they would want to incorporate anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation = df.drop(columns=[\"artists\",\"id\",\"name\",\"feature_artist\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target feature will be popularity (how can we maximize it?), the other features will determine how best to maximize popularity so they will be the features that we compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = preparation.popularity\n",
    "features = preparation.drop(columns=[\"popularity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling our non-popularity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and testing data in preparation for modeling and the conclusion of the project. As stated above, we will be implementing regression models to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Modeling <br />\n",
    "\n",
    "Here we will test some of the most popular regression machine learning models. first we import all of the models modules and train them with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "r = Ridge().fit(X_train, y_train)\n",
    "l = Lasso().fit(X_train, y_train)\n",
    "rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "knn = KNeighborsRegressor().fit(X_train, y_train)\n",
    "sv = SVR().fit(X_train, y_train)\n",
    "nn = MLPRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check the score, predictions, r^2 score, explained variance score, and mean absolute error for all of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression Score: 0.19140385952675698\n",
      "\n",
      " predictions: [52.36067904 46.12238296 47.8112182  55.52120398 49.59117454 54.24344913\n",
      " 47.32301572 49.20127545 45.57957551 47.8426646  51.37704596 51.73906102\n",
      " 50.1519536  49.32706049 49.65194156 47.53693472 46.78374365 51.32005343\n",
      " 50.93056483 44.15446007 56.51506345 47.74462297 44.57780843 48.20795386\n",
      " 57.87092072 53.47258141 53.11702266 43.93373503 45.38026224 48.55912001\n",
      " 51.00801367 44.89865745 50.01800176 50.69294819 51.19260663 50.16459423\n",
      " 52.88750595 49.02246016 48.58303064 49.64889352 46.17943798] \n",
      "\n",
      "\t r2_score : 0.013541704007281274\n",
      "\t explained_variance_score : 0.013782877228005752\n",
      "\t mean_absolute_error : 6.129081903733724\n",
      "----------------------------------\n",
      "Ridge Score: 0.19139185258337932\n",
      "\n",
      " predictions: [52.34361901 46.15505061 47.73489254 55.48326273 49.60136684 54.21573216\n",
      " 47.32681931 49.19396712 45.62613978 47.80911602 51.35394376 51.73629579\n",
      " 50.14643236 49.31676498 49.6692289  47.55194373 46.81611212 51.29946775\n",
      " 50.92155847 44.19283154 56.48318048 47.77025938 44.60698027 48.209501\n",
      " 57.62668901 53.44492026 53.08889998 43.96861499 45.41828382 48.55672958\n",
      " 51.01072378 44.93748271 50.04904941 50.69274514 51.18229602 50.13531772\n",
      " 52.86935527 49.03059945 48.60391389 49.64490658 46.20743765] \n",
      "\n",
      "\t r2_score : 0.01391598070482436\n",
      "\t explained_variance_score : 0.014179165501589153\n",
      "\t mean_absolute_error : 6.1338248690553545\n",
      "----------------------------------\n",
      "Lasso Score: 0.13468684789460306\n",
      "\n",
      " predictions: [51.32438982 47.83544749 46.64689379 53.10615344 49.84126521 52.31662944\n",
      " 47.25930835 49.27589513 47.67540884 48.34757116 49.91604972 51.14301269\n",
      " 49.94805745 49.45727226 51.76182879 50.70547391 49.84126521 51.17492061\n",
      " 49.98006518 47.36600079 54.04494703 47.97958208 47.51537019 49.48927999\n",
      " 49.7880188  52.07123685 51.34572831 47.53670868 47.50470095 48.47560208\n",
      " 51.1962591  48.81711767 50.22535797 49.57463394 50.6522275  49.89461143\n",
      " 51.54834412 49.89461143 49.4679415  48.46930034 48.59296376] \n",
      "\n",
      "\t r2_score : -0.004124354646640516\n",
      "\t explained_variance_score : -0.004081374895124279\n",
      "\t mean_absolute_error : 6.2388146491046905\n",
      "----------------------------------\n",
      "RandomForestRegressor Score: 0.8676443854268774\n",
      "\n",
      " predictions: [54.96 47.89 47.63 51.95 51.14 53.02 48.68 49.68 47.07 48.99 48.04 50.49\n",
      " 50.56 48.5  59.65 50.22 49.77 55.2  48.56 46.98 53.14 47.96 47.25 47.57\n",
      " 46.97 53.3  52.92 45.68 45.94 49.01 53.08 49.42 52.11 50.21 53.2  53.68\n",
      " 52.73 53.   46.47 46.54 47.21] \n",
      "\n",
      "\t r2_score : -0.21291509246816398\n",
      "\t explained_variance_score : -0.2089135044047694\n",
      "\t mean_absolute_error : 6.943658536585366\n",
      "----------------------------------\n",
      "KNeighborsRegressor Score: 0.20483526366378935\n",
      "\n",
      " predictions: [49.6 48.4 46.  55.8 46.8 53.2 51.2 57.  45.8 52.4 57.  52.4 56.6 46.\n",
      " 52.2 49.2 44.2 48.4 42.8 45.  56.4 48.  45.8 50.  44.8 50.  47.6 47.\n",
      " 47.2 48.8 48.8 50.8 47.8 49.4 53.8 46.  48.2 46.4 51.8 49.6 46.2] \n",
      "\n",
      "\t r2_score : -0.06379087476802958\n",
      "\t explained_variance_score : -0.06209765150060775\n",
      "\t mean_absolute_error : 6.170731707317073\n",
      "----------------------------------\n",
      "SVR Score: 0.1475232938610439\n",
      "\n",
      " predictions: [49.27170233 47.56370193 48.92505859 51.28599423 49.13654792 50.95682466\n",
      " 47.72655086 48.98705657 47.27255834 49.71599261 49.5263765  50.19630038\n",
      " 48.5396534  48.11642289 50.44098505 49.60422249 48.92388315 49.66290292\n",
      " 48.37923401 46.904913   50.93852378 47.65449481 47.74370989 48.97441829\n",
      " 49.63309837 49.97689384 48.99451172 48.41200079 48.72003292 48.81436712\n",
      " 50.79028215 49.80683979 50.50382564 48.98269715 49.31086755 48.74454584\n",
      " 51.03407549 48.25447789 48.38095197 47.52899678 48.45435333] \n",
      "\n",
      "\t r2_score : -0.004239735143258816\n",
      "\t explained_variance_score : 0.0020110177440711974\n",
      "\t mean_absolute_error : 6.239641228463357\n",
      "----------------------------------\n",
      "MLPRegressor Score: -21.012074475033145\n",
      "\n",
      " predictions: [12.21582699  8.96646311  6.32100521 14.88302286 13.10743782 13.65880024\n",
      "  6.60919024 13.26591125  7.52196168 15.27474551 10.4337856  14.06510332\n",
      " 11.03772097  9.57865658 18.93006295 16.40708214 15.77339359  9.89117936\n",
      "  9.03428864 10.58463177 18.93873023 15.0945243   8.42287818 14.35426758\n",
      "  2.58937913 13.85504298 20.30371924 16.48046266 17.7984408  11.33194523\n",
      " 10.6944411  18.07444679 15.52750641 15.45733251 10.38627331  9.38007626\n",
      " 10.14244291  8.13758816 12.24936676  9.24486254 15.47280352] \n",
      "\n",
      "\t r2_score : -25.235396781641356\n",
      "\t explained_variance_score : -0.4155335975621708\n",
      "\t mean_absolute_error : 37.20739511120221\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "models = [lr, r, l, rf, knn, sv, nn]\n",
    "metrics = {\"r2_score\": metrics.r2_score, \"explained_variance_score\": metrics.explained_variance_score, \"mean_absolute_error\":metrics.mean_absolute_error}\n",
    "\n",
    "for model in models:\n",
    "    print(str(model).strip(\"()\"), 'Score:', str(model.score(X_train,y_train)))\n",
    "    print(\"\\n predictions:\", model.predict(X_test),\"\\n\")\n",
    "    for k, metric in metrics.items():\n",
    "        print(\"\\t\", k, \":\", metric(y_test, model.predict(X_test)))\n",
    "    print('-'*34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the Random Forest performs the best. This will be the best model to use for our general conclusions and moving forward with the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### Part II: Utilizing Model for Prediction\n",
    "The goal of this project was to see if we could increase popularity with different feature input. We will randomly generate a new dataframe with each of the features and see if we can exceed our max popularity of 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>feature_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>The Chainsmokers, ILLENIUM, Lennon Stella</td>\n",
       "      <td>3g0mEQx3NTanacLseoP0Gw</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>76</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.511</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-8.144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.351</td>\n",
       "      <td>100.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ILLENIUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       artists                      id  \\\n",
       "212  The Chainsmokers, ILLENIUM, Lennon Stella  3g0mEQx3NTanacLseoP0Gw   \n",
       "\n",
       "         name  popularity  danceability  energy  key  loudness  mode  \\\n",
       "212  Takeaway          76         0.528   0.511  3.0    -8.144   1.0   \n",
       "\n",
       "     speechiness  acousticness  instrumentalness  liveness  valence  tempo  \\\n",
       "212       0.0324         0.126               0.0     0.101    0.351  100.1   \n",
       "\n",
       "     time_signature feature_artist  \n",
       "212             4.0       ILLENIUM  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='popularity',ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the randomly generated dataframe utilizing the min and max values for each feature as a range. This is making the assumption that anything out of this range is unrealistic while making the track (whether that be from constraints within genre, technology, or simply creativity level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-11.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>195.77</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.50</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>73.22</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.97</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>124.42</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.16</td>\n",
       "      <td>140.50</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.20</td>\n",
       "      <td>-14.55</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>98.43</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy    key  loudness  mode  speechiness  acousticness  \\\n",
       "0          0.50    0.92   1.22    -11.04  0.50         0.04          0.36   \n",
       "1          0.72    0.50  10.50     -2.55  0.33         0.06          0.73   \n",
       "2          0.27    0.15   2.97     -6.16  0.56         0.33          0.19   \n",
       "3          0.78    0.92   1.54     -5.44  0.80         0.23          0.59   \n",
       "4          0.82    0.72   2.20    -14.55  0.39         0.12          0.63   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  time_signature  \n",
       "0              0.23      0.55     0.20  195.77            3.46  \n",
       "1              0.63      0.48     0.48   73.22            2.54  \n",
       "2              0.54      0.25     0.79  124.42            3.11  \n",
       "3              0.60      0.59     0.16  140.50            1.92  \n",
       "4              0.79      0.12     0.56   98.43            3.32  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_df = pd.DataFrame(columns = list(features.columns))\n",
    "\n",
    "for x in range(1000):\n",
    "    rand_dict = {}\n",
    "    for feature in list(features.columns):\n",
    "        feat_min = int(df[feature].min()*100)\n",
    "        feat_max = int(df[feature].max()*100)\n",
    "        rand_float = float(np.random.randint(feat_min, feat_max)/100)\n",
    "        rand_dict[feature] = rand_float\n",
    "    rand_df = rand_df.append(rand_dict, ignore_index = True)\n",
    "        \n",
    "        \n",
    "rand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add feature/column for the new predicted popularity for each randomly generated/simulated song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_df['pred_popularity'] = rf.predict(rand_df.loc[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>pred_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.36</td>\n",
       "      <td>-13.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>126.74</td>\n",
       "      <td>2.85</td>\n",
       "      <td>57.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-10.54</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.96</td>\n",
       "      <td>88.49</td>\n",
       "      <td>3.16</td>\n",
       "      <td>57.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>-11.77</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>111.06</td>\n",
       "      <td>3.79</td>\n",
       "      <td>57.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.82</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>110.22</td>\n",
       "      <td>3.10</td>\n",
       "      <td>57.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.75</td>\n",
       "      <td>-9.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>112.32</td>\n",
       "      <td>1.92</td>\n",
       "      <td>57.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n",
       "287          0.30    0.06  3.36    -13.76  0.79         0.15          0.10   \n",
       "302          0.87    0.92  1.38    -10.54  0.49         0.26          0.04   \n",
       "696          0.17    0.77  8.46    -11.77  0.03         0.29          0.00   \n",
       "824          0.81    0.75  9.82     -3.04  0.29         0.14          0.11   \n",
       "776          0.87    0.73  7.75     -9.54  0.63         0.05          0.31   \n",
       "\n",
       "     instrumentalness  liveness  valence   tempo  time_signature  \\\n",
       "287              0.80      0.68     0.67  126.74            2.85   \n",
       "302              0.51      0.67     0.96   88.49            3.16   \n",
       "696              0.07      0.68     0.85  111.06            3.79   \n",
       "824              0.57      0.66     0.69  110.22            3.10   \n",
       "776              0.21      0.67     0.67  112.32            1.92   \n",
       "\n",
       "     pred_popularity  \n",
       "287            57.63  \n",
       "302            57.41  \n",
       "696            57.20  \n",
       "824            57.16  \n",
       "776            57.14  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_df.sort_values(by='pred_popularity',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illenium Average Popularity 62.5\n",
      "--------------------\n",
      "Nurko Average Popularity 49\n",
      "ARMNHMR Average Popularity 42\n",
      "William Black Average Popularity 50\n",
      "Said The Sky Average Popularity 54\n",
      "Seven Lions Average Popularity 52\n",
      "MitiS Average Popularity 45\n",
      "Crystal Skies Average Popularity 41\n",
      "ILLENIUM Average Popularity 62\n",
      "Dabin Average Popularity 49\n",
      "Slushii Average Popularity 52\n",
      "Kasbo Average Popularity 49\n",
      "Skrux Average Popularity 37\n",
      "Jai Wolf Average Popularity 52\n",
      "Crywolf Average Popularity 40\n",
      "Ekali Average Popularity 46\n",
      "INZO Average Popularity 44\n",
      "Zeds Dead Average Popularity 55\n",
      "Lost Kings Average Popularity 57\n",
      "Kaivon Average Popularity 45\n",
      "NGHTMRE Average Popularity 57\n",
      "San Holo Average Popularity 52\n"
     ]
    }
   ],
   "source": [
    "print('Illenium Average Popularity', float(df.loc[df['feature_artist'] == 'ILLENIUM',['popularity']].mean()))\n",
    "print('-'*20)\n",
    "for artist in list(df['feature_artist'].unique()):\n",
    "    print(artist, 'Average Popularity', int(df.loc[df['feature_artist'] == artist,['popularity']].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the highest popularity that we can randomly generate within the specified constraints is only 58.53. Where Illenium tracks already have an average popularity of 62.5, he is exceeding this and can probably do without utilizing the analysis/modeling. This model would be more useful for any artist that has an average popularity below 57 (essentially all of the artists that were included in this analysis other than Illenium, Lost Kings, and NGHTMRE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
